{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9e613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2099d34",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d217e85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Problem</th>\n",
       "      <th>Solution</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-II-4</td>\n",
       "      <td>Let $x,y$ and $z$ be positive real numbers tha...</td>\n",
       "      <td>Denote $\\log_2(x) = a$, $\\log_2(y) = b$, and $...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-II-12</td>\n",
       "      <td>Let $O(0,0), A(\\tfrac{1}{2}, 0),$ and $B(0, \\t...</td>\n",
       "      <td>Begin by finding the equation of the line $\\ov...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-I-4</td>\n",
       "      <td>Jen enters a lottery by picking $4$ distinct n...</td>\n",
       "      <td>This is a conditional probability problem. Bay...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-I-3</td>\n",
       "      <td>Alice and Bob play the following game. A stack...</td>\n",
       "      <td>Let's first try some experimentation. Alice ob...</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-I-8</td>\n",
       "      <td>Eight circles of radius $34$ are sequentially ...</td>\n",
       "      <td>Draw an altitude from both end circles of the ...</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                            Problem  \\\n",
       "0   2024-II-4  Let $x,y$ and $z$ be positive real numbers tha...   \n",
       "1  2024-II-12  Let $O(0,0), A(\\tfrac{1}{2}, 0),$ and $B(0, \\t...   \n",
       "2    2024-I-4  Jen enters a lottery by picking $4$ distinct n...   \n",
       "3    2024-I-3  Alice and Bob play the following game. A stack...   \n",
       "4    2024-I-8  Eight circles of radius $34$ are sequentially ...   \n",
       "\n",
       "                                            Solution  Answer  \n",
       "0  Denote $\\log_2(x) = a$, $\\log_2(y) = b$, and $...      33  \n",
       "1  Begin by finding the equation of the line $\\ov...      23  \n",
       "2  This is a conditional probability problem. Bay...     116  \n",
       "3  Let's first try some experimentation. Alice ob...     809  \n",
       "4  Draw an altitude from both end circles of the ...     197  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "aime = load_dataset(\"Maxwell-Jia/AIME_2024\")\n",
    "aime_df = pd.DataFrame(aime['train'])\n",
    "aime_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86e0b7",
   "metadata": {},
   "source": [
    "### Test Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c305d0b2",
   "metadata": {},
   "source": [
    "Let $x,y$ and $z$ be positive real numbers that satisfy the following system of equations: \n",
    "$$[\\log_2\\left({x \\over yz}\\right) = 1/ 2 ]$$\n",
    "$$[\\log_2\\left({y \\over xz}\\right) = {1 / 3}]$$\n",
    "$$[\\log_2\\left({z \\over xy}\\right) = {1 \\over 4}]$$\n",
    "Then the value of $\\left|\\log_2(x^4y^3z^2)\\right|$ is $\\tfrac{m}{n}$ where $m$ and $n$ are relatively prime positive integers. Find $m+n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa3c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let $x,y$ and $z$ be positive real numbers that satisfy the following system of equations: \n",
      "\\[\\log_2\\left({x \\over yz}\\right) = {1 \\over 2}\\]\n",
      "\\[\\log_2\\left({y \\over xz}\\right) = {1 \\over 3}\\]\n",
      "\\[\\log_2\\left({z \\over xy}\\right) = {1 \\over 4}\\]\n",
      "Then the value of $\\left|\\log_2(x^4y^3z^2)\\right|$ is $\\tfrac{m}{n}$ where $m$ and $n$ are relatively prime positive integers. Find $m+n$.\n"
     ]
    }
   ],
   "source": [
    "print(aime_df.iloc[0]['Problem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbdfa48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Denote $\\log_2(x) = a$, $\\log_2(y) = b$, and $\\log_2(z) = c$.\n",
       "> \n",
       "> Then, we have:\n",
       "> $a-b-c = \\frac{1}{2}$,\n",
       "> $-a+b-c = \\frac{1}{3}$,\n",
       "> $-a-b+c = \\frac{1}{4}$.\n",
       "> \n",
       "> Now, we can solve to get $a = \\frac{-7}{24}, b = \\frac{-9}{24}, c = \\frac{-5}{12}$.\n",
       "> Plugging these values in, we obtain $|4a + 3b + 2c|  = \\frac{25}{8} \\implies \\boxed{033}$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(aime_df.iloc[0]['Solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb8d7149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denote $\\log_2(x) = a$, $\\log_2(y) = b$, and $\\log_2(z) = c$.\n",
      "\n",
      "Then, we have:\n",
      "$a-b-c = \\frac{1}{2}$,\n",
      "$-a+b-c = \\frac{1}{3}$,\n",
      "$-a-b+c = \\frac{1}{4}$.\n",
      "\n",
      "Now, we can solve to get $a = \\frac{-7}{24}, b = \\frac{-9}{24}, c = \\frac{-5}{12}$.\n",
      "Plugging these values in, we obtain $|4a + 3b + 2c|  = \\frac{25}{8} \\implies \\boxed{033}$.\n"
     ]
    }
   ],
   "source": [
    "print(aime_df.iloc[0]['Solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf0105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = [\"deepscaler-1.5B\", \"DeepSeek-R1-Distill-Qwen-1.5B\"]\n",
    "# for m_name in model_names:\n",
    "#     print(f\"Evaluating raw performance for {m_name}\")\n",
    "#     model, tokenizer = load_model_and_tokenizer(m_name)\n",
    "#     acc = evaluate_model_raw(model, tokenizer, pd.DataFrame(aime['train']), num_samples=1)\n",
    "#     print(f\"{m_name} raw accuracy: {acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8561aaf3",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab0cd15",
   "metadata": {},
   "source": [
    "### Unsloth experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40ccf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-05 03:15:00 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from utils.benchmark import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2602f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 11201.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03333333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "evaluate_performance_math(\n",
    "    aime_df,\n",
    "    foo_model,\n",
    "    '{}',\n",
    "    metric='best',\n",
    "    num_samples=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08514642",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = aime_df.iloc[0]\n",
    "question = row['Problem']\n",
    "ground_truth = row['Answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5523c7",
   "metadata": {},
   "source": [
    "#### Vanilla R1-Distill-QWEN-1.5B\n",
    "\n",
    "20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 4096 # Can increase for longer reasoning traces\n",
    "lora_rank = 16 # Larger rank = smarter, but slower\n",
    "\n",
    "# model_id = \"meta-llama/meta-Llama-3.1-8B-Instruct\"\n",
    "# model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True, # False for LoRA 16bit\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.6, # Reduce if out of memory\n",
    "    # max_logprobs = 1000\n",
    ")\n",
    "\n",
    "vanilla_1p5B = FastMathModel(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    sampling_params=SamplingParams(\n",
    "                    temperature=1.0,\n",
    "                    top_p=0.9,\n",
    "                    max_tokens=20000)\n",
    ")\n",
    "\n",
    "# Deprecated Naive Experiment: SLOW!!\n",
    "# system_prompt = r'''Assume you are a professional mathematician.{}\n",
    "# Please show your step by step reasoning in <thinking> tag, keep your \n",
    "# solution concise skipping arithmetic details, and generate your answer as \n",
    "# a number in <answer> tag.'''\n",
    "# prompt = system_prompt.format(question)\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# sampling_params = SamplingParams(\n",
    "#     temperature = 0.5,\n",
    "#     top_p = 0.99,\n",
    "#     max_tokens = 2048,\n",
    "# )\n",
    "\n",
    "# outputs = model.generate(**inputs,\n",
    "#                         #  streamer = text_streamer,\n",
    "#                         # sampling_params=sampling_params, \n",
    "#                          max_new_tokens = 2048)\n",
    "\n",
    "# # outputs = model.fast_generate(inputs, sampling_params=sampling_params)\n",
    "\n",
    "# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a219ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vanilla\n",
    "vanilla_1p5B_perf = evaluate_performance_math(\n",
    "                    aime_df,\n",
    "                    vanilla_1p5B.generate,\n",
    "                    get_prompt_template(),\n",
    "                    metric='best',\n",
    "                    num_samples=1\n",
    "                )\n",
    "print(f\"Vanilla 1.5B performance: {vanilla_1p5B_perf*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "101e5b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla 1.5B performance: 20.0000%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vanilla 1.5B performance: {vanilla_1p5B_perf*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5cb15",
   "metadata": {},
   "source": [
    "#### Less Thought Switch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8869c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm.logits_process import LogitsProcessor\n",
    "\n",
    "class LessThoughtSwitchModel(FastMathModel):\n",
    "    def __init__(self, model, tokenizer, sampling_params=None, max_tokens=20000):\n",
    "        if sampling_params is None:\n",
    "            sampling_params = SamplingParams(\n",
    "                temperature = 0.6,\n",
    "                repetition_penalty = 1.1,\n",
    "                top_p = 0.9,\n",
    "                max_tokens = max_tokens,\n",
    "                logits_processors = [self._penalize_thought_switch]\n",
    "            )\n",
    "        super().__init__(model, tokenizer, sampling_params)\n",
    "        self.penalized_tokens = self._thought_switch_penalty()\n",
    "        if sampling_params.logits_processors is None:\n",
    "            sampling_params.logits_processors = [self._penalize_thought_switch]\n",
    "        self.sampling_params = sampling_params\n",
    "        \n",
    "\n",
    "    def _thought_switch_penalty(self):\n",
    "        custom_penalties = {\n",
    "            \"Wait\": 3.0,  # Strong penalty for \"Wait\"\n",
    "            \"wait\": 3.0,\n",
    "            \"Hmm\": 3.0,   # Strong penalty for hesitation markers\n",
    "            \"hmm\": 3.0\n",
    "        }\n",
    "        # Get token IDs for penalized tokens\n",
    "        penalized_tokens = {}\n",
    "        for word, penalty in custom_penalties.items():\n",
    "            token_ids = self.tokenizer.encode(word, add_special_tokens=False)\n",
    "            for token_id in token_ids:\n",
    "                penalized_tokens[token_id] = penalty\n",
    "        return penalized_tokens\n",
    "\n",
    "    def _penalize_thought_switch(self, token_ids, logits):\n",
    "        for token_id, penalty in self.penalized_tokens.items():\n",
    "            logits[token_id] -= penalty\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b9682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.10s/it, est. speed input: 8.83 toks/s, output: 77.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:51<00:00, 51.25s/it, est. speed input: 5.46 toks/s, output: 74.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.42s/it, est. speed input: 8.85 toks/s, output: 76.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:40<00:00, 40.43s/it, est. speed input: 4.92 toks/s, output: 75.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:51<00:00, 51.59s/it, est. speed input: 3.78 toks/s, output: 75.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.57s/it, est. speed input: 15.73 toks/s, output: 77.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:34<00:00, 34.72s/it, est. speed input: 5.10 toks/s, output: 75.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.32s/it, est. speed input: 15.20 toks/s, output: 77.78 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.55s/it, est. speed input: 12.99 toks/s, output: 74.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.85s/it, est. speed input: 7.77 toks/s, output: 78.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.61s/it, est. speed input: 8.97 toks/s, output: 74.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.56s/it, est. speed input: 19.04 toks/s, output: 76.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 18.00s/it, est. speed input: 13.06 toks/s, output: 73.68 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:51<00:00, 51.42s/it, est. speed input: 3.34 toks/s, output: 76.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:37<00:00, 37.16s/it, est. speed input: 4.17 toks/s, output: 77.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:38<00:00, 38.42s/it, est. speed input: 4.32 toks/s, output: 59.98 toks/s]\n",
      " 53%|█████▎    | 16/30 [07:41<07:42, 33.02s/it]"
     ]
    }
   ],
   "source": [
    "# # import gc\n",
    "# # gc.collect()\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name = model_id,\n",
    "#     max_seq_length = max_seq_length,\n",
    "#     load_in_4bit = True, # False for LoRA 16bit\n",
    "#     fast_inference = True, # Enable vLLM fast inference\n",
    "#     max_lora_rank = lora_rank,\n",
    "#     gpu_memory_utilization = 0.6, # Reduce if out of memory\n",
    "#     # max_logprobs = 1000\n",
    "# )\n",
    "\n",
    "lessThoughtSw_1p5B = LessThoughtSwitchModel(\n",
    "                                model,\n",
    "                                tokenizer,\n",
    "                                max_tokens=20000,\n",
    "                            )\n",
    "# sampling_params = SamplingParams(\n",
    "#     temperature = 0.6,\n",
    "#     repetition_penalty = 1.1,\n",
    "#     top_p = 0.9,\n",
    "#     max_tokens = max_tokens,\n",
    "#     logits_processors = [self._thought_switch_penalty]\n",
    "# )\n",
    "\n",
    "# Less Thought Switch Model\n",
    "lessTSW_1p5B_perf = evaluate_performance_math(\n",
    "                    aime_df,\n",
    "                    lessThoughtSw_1p5B.generate,\n",
    "                    get_prompt_template(),\n",
    "                    metric='best',\n",
    "                    num_samples=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59d08f",
   "metadata": {},
   "source": [
    "#### Penalized Original Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97beaf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_penalties = {\n",
    "    \"Wait\": 3.0,  # Strong penalty for \"Wait\"\n",
    "    \"wait\": 3.0,\n",
    "    \"Hmm\": 3.0,   # Strong penalty for hesitation markers\n",
    "    \"hmm\": 3.0\n",
    "}\n",
    "# Get token IDs for penalized tokens\n",
    "penalized_tokens = {}\n",
    "for word, penalty in custom_penalties.items():\n",
    "    token_ids = tokenizer.encode(word, add_special_tokens=False)\n",
    "    for token_id in token_ids:\n",
    "        penalized_tokens[token_id] = penalty\n",
    "\n",
    "\n",
    "def penalize_thought_switch(token_ids, logits):\n",
    "    for token_id, penalty in penalized_tokens.items():\n",
    "        logits[token_id] -= penalty\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23ca64e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 2/2 [01:19<00:00, 39.64s/it, est. speed input: 6.11 toks/s, output: 55.16 toks/s]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = r'''Assume you are a professional mathematician.{}\n",
    "Please show your step by step reasoning in <think> tag. keep your \n",
    "solution concise skipping arithmetic details, and generate your answer as \n",
    "a number in <answer> tag.\n",
    "Constraint: Please keep your response in the following format:\n",
    "<think>\n",
    "[your reasoning]\n",
    "</think>\n",
    "[your derivation, keep this short] \n",
    "<answer>\n",
    "[succinct answer]\n",
    "</answer>\n",
    "'''\n",
    "prompt = system_prompt.format(question)\n",
    "\n",
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"user\", \"content\" : prompt},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.5,\n",
    "    repetition_penalty=1.1,\n",
    "    # frequency_penalty=0.1,\n",
    "    top_p = 0.9,\n",
    "    max_tokens = 20000,\n",
    "    logits_processors=[penalize_thought_switch]\n",
    ")\n",
    "output = model.fast_generate(\n",
    "    [text],\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = None,\n",
    ")[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afc04de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Okay, so I have this problem here with three logarithmic equations involving variables x, y, and z. The goal is to find the absolute value of log base 2 of (x⁴y³z²). Hmm, let's see how to approach this.\n",
       "> \n",
       "> First, the equations given are:\n",
       "> \n",
       "> 1. log₂(x / yz) = 1/2\n",
       "> 2. log₂(y / xz) = 1/3\n",
       "> 3. log₂(z / xy) = 1/4\n",
       "> \n",
       "> I remember that logarithms can be converted into exponents if needed, which might help simplify things. Let me rewrite each equation using exponent form instead of logs.\n",
       "> \n",
       "> Starting with the first equation:\n",
       "> log₂(x / yz) = 1/2 means that 2^(1/2) = x / yz. So,\n",
       "> √2 = x / yz → x = √2 * yz.\n",
       "> \n",
       "> Second equation:\n",
       "> log₂(y / xz) = 1/3 ⇒ 2^(1/3) = y / xz. Thus,\n",
       "> 2^(1/3) = y / xz → y = 2^(1/3) * xz.\n",
       "> \n",
       "> Third equation:\n",
       "> log₂(z / xy) = 1/4 ⇒ 2^(1/4) = z / xy. Hence,\n",
       "> 2^(1/4) = z / xy → z = 2^(1/4) * xy.\n",
       "> \n",
       "> Now, we have expressions for x, y, and z in terms of each other. It seems like substitution might work here. Maybe express all variables in terms of one variable and solve?\n",
       "> \n",
       "> Let me try expressing everything in terms of x. From the first equation, x = √2 * yz. If I can express y and z in terms of x, then perhaps substitute back.\n",
       "> \n",
       "> But looking at the second equation, y = 2^(1/3)*xz. Similarly, from the third equation, z = 2^(1/4)*xy.\n",
       "> \n",
       "> This seems cyclical because each variable depends on the product of two others. Maybe multiplying them together could lead somewhere? Let's think about it.\n",
       "> \n",
       "> If I multiply all three original logarithmic equations:\n",
       "> \n",
       "> log₂(x / yz) + log₂(y / xz) + log₂(z / xy) = 1/2 + 1/3 + 1/4.\n",
       "> \n",
       "> Recall that log(a) + log(b) + log(c) = log(abc), but wait, actually, each term is log of something, so when adding logs, it becomes the log of the product. However, since these are individual logs set equal to specific values, maybe another approach would be better.\n",
       "> \n",
       "> Alternatively, maybe convert each equation into exponential form and then take the ratio or something to eliminate variables.\n",
       "> \n",
       "> Let me define:\n",
       "> \n",
       "> Equation 1: log₂(x / yz) = 1/2 ⇒ x / yz = 2^{1/2} ⇒ x = yz * sqrt(2).\n",
       "> \n",
       "> Equation 2: log₂(y / xz) = 1/3 ⇒ y / xz = 2^{1/3} ⇒ y = xz * 2^{1/3}.\n",
       "> \n",
       "> Equation 3: log₂(z / xy) = 1/4 ⇒ z / xy = 2^{1/4} ⇒ z = xy * 2^{1/4}.\n",
       "> \n",
       "> So now, each variable is expressed in terms of products. Let me write them again:\n",
       "> \n",
       "> x = yz * sqrt(2),\n",
       "> y = xz * 2^{1/3},\n",
       "> z = xy * 2^{1/4}.\n",
       "> \n",
       "> This looks similar to a cyclic dependency. Maybe substituting one into another will help.\n",
       "> \n",
       "> From Equation 1: x = yz * sqrt(2).\n",
       "> \n",
       "> Plug this into Equation 2: y = (yz * sqrt(2)) * z * 2^{1/3}.\n",
       "> \n",
       "> Simplify: y = yz² * sqrt(2) * 2^{1/3}.\n",
       "> \n",
       "> Divide both sides by y (assuming y ≠ 0, which it isn't):\n",
       "> \n",
       "> 1 = z² * sqrt(2) * 2^{1/3}.\n",
       "> \n",
       "> Similarly, from Equation 3: z = (yz * sqrt(2)) * y * 2^{1/4}.\n",
       "> \n",
       "> Which simplifies to: z = y²z * sqrt(2) * 2^{1/4}.\n",
       "> \n",
       "> Divide both sides by z:\n",
       "> \n",
       "> 1 = y² * sqrt(2) * 2^{1/4}.\n",
       "> \n",
       "> Now, we have two equations:\n",
       "> \n",
       "> 1 = z² * sqrt(2) * 2^{1/3}   ...(A)\n",
       "> 1 = y² * sqrt(2) * 2^{1/4}   ...(B)\n",
       "> \n",
       "> Let me compute the constants:\n",
       "> \n",
       "> sqrt(2) is 2^{1/2}, so 2^{1/2} * 2^{1/3} = 2^{5/6}; similarly,\n",
       "> \n",
       "> sqrt(2) * 2^{1/4} = 2^{1/2} * 2^{1/4} = 2^{3/4}.\n",
       "> \n",
       "> Thus, Equations become:\n",
       "> \n",
       "> 1 = z² * 2^{5/6}  ...(A)\n",
       "> 1 = y² * 2^{3/4}   ...(B)\n",
       "> \n",
       "> Therefore, solving for z² and y²:\n",
       "> \n",
       "> z² = 2^{-5/6}\n",
       "> y² = 2^{-3/4}\n",
       "> \n",
       "> Taking square roots:\n",
       "> \n",
       "> z = 2^{-5/12}\n",
       "> y = 2^{-3/8}\n",
       "> \n",
       "> Since all variables are positive, no issues with signs.\n",
       "> \n",
       "> Now, recall from Equation 1: x = yz * sqrt(2).\n",
       "> \n",
       "> Compute yz:\n",
       "> \n",
       "> yz = (2^{-3/8})(2^{-5/12}) = 2^{-3/8 -5/12}. Let's calculate the exponent:\n",
       "> \n",
       "> Convert to common denominator: 24.\n",
       "> \n",
       "> -3/8 = -9/24; -5/12 = -10/24. Sum: -19/24.\n",
       "> \n",
       "> So yz = 2^{-19/24}.\n",
       "> \n",
       "> Multiply by sqrt(2) = 2^{1/2}:\n",
       "> \n",
       "> x = 2^{-19/24} * 2^{1/2} = 2^{-19/24 + 12/24} = 2^{-7/24}.\n",
       "> \n",
       "> Thus, x = 2^{-7/24}.\n",
       "> \n",
       "> Now, having found x, y, z in terms of powers of 2:\n",
       "> \n",
       "> x = 2^{-7/24},\n",
       "> \n",
       "> y = 2^{-3/8} = 2^{-9/24},\n",
       "> \n",
       "> z = 2^{-5/12} = 2^{-10/24}.\n",
       "> \n",
       "> To compute log₂(x⁴y³z²), let's compute the expression inside:\n",
       "> \n",
       "> x⁴y³z² = (2^{-7/24})⁴ * (2^{-9/24})³ * (2^{-10/24})².\n",
       "> \n",
       "> Exponent rules:\n",
       "> \n",
       "> When multiplying same bases, add exponents.\n",
       "> \n",
       "> Compute exponents:\n",
       "> \n",
       "> For x⁴: (-7/24)*4 = -28/24 = -7/6.\n",
       "> \n",
       "> For y³: (-9/24)*3 = -27/24 = -9/8.\n",
       "> \n",
       "> For z²: (-10/24)*2 = -20/24 = -5/12.\n",
       "> \n",
       "> Add them up:\n",
       "> \n",
       "> -7/6 - 9/8 -5/12.\n",
       "> \n",
       "> Find a common denominator, which is 24.\n",
       "> \n",
       "> Convert each fraction:\n",
       "> \n",
       "> -7/6 = -28/24,\n",
       "> \n",
       "> -9/8 = -27/24,\n",
       "> \n",
       "> -5/12 = -10/24.\n",
       "> \n",
       "> Sum: (-28 -27 -10)/24 = (-65)/24.\n",
       "> \n",
       "> Thus, x⁴y³z² = 2^{-65/24}.\n",
       "> \n",
       "> Therefore, log₂(x⁴y³z²) = log₂(2^{-65/24}) = -65/24.\n",
       "> \n",
       "> The absolute value is | -65/24 | = 65/24.\n",
       "> \n",
       "> Check if 65 and 24 are coprime. Prime factors of 65 are 5 and 13; 24 is 2³×3¹. No common factors, so m=65, n=24. Therefore, m+n=89.\n",
       "> \n",
       "> **Final Answer**\n",
       "> \\boxed{89}\n",
       "> </think>\n",
       "> \n",
       "> Given the system of equations involving logarithms:\n",
       "> \n",
       "> 1. \\(\\log_2\\left(\\frac{x}{yz}\\right) = \\frac{1}{2}\\)\n",
       "> 2. \\(\\log_2\\left(\\frac{y}{xz}\\right) = \\frac{1}{3}\\)\n",
       "> 3. \\(\\log_2\\left(\\frac{z}{xy}\\right) = \\frac{1}{4}\\)\n",
       "> \n",
       "> We convert these logarithmic equations to their exponential forms:\n",
       "> \n",
       "> 1. \\(x = yz \\cdot \\sqrt{2}\\)\n",
       "> 2. \\(y = xz \\cdot 2^{1/3}\\)\n",
       "> 3. \\(z = xy \\cdot 2^{1/4}\\)\n",
       "> \n",
       "> Next, we express each variable in terms of the others and substitute:\n",
       "> \n",
       "> From the first equation, \\(x = yz \\cdot \\sqrt{2}\\).\n",
       "> \n",
       "> Substituting into the second equation:\n",
       "> \\[ y = (yz \\cdot \\sqrt{2}) \\cdot z \\cdot 2^{1/3} \\]\n",
       "> \\[ 1 = z^2 \\cdot \\sqrt{2} \\cdot 2^{1/3} \\]\n",
       "> \n",
       "> From the third equation, \\(z = xy \\cdot 2^{1/4}\\).\n",
       "> \n",
       "> Substituting into the second equation:\n",
       "> \\[ 1 = y^2 \\cdot \\sqrt{2} \\cdot 2^{1/4} \\]\n",
       "> \n",
       "> Converting the constants:\n",
       "> \\[ \\sqrt{2} = 2^{1/2} \\]\n",
       "> \\[ 2^{1/2} \\cdot 2^{1/3} = 2^{5/6} \\]\n",
       "> \\[ 2^{1/2} \\cdot 2^{1/4} = 2^{3/4} \\]\n",
       "> \n",
       "> Thus, we get:\n",
       "> \\[ 1 = z^2 \\cdot 2^{5/6} \\]\n",
       "> \\[ 1 = y^2 \\cdot 2^{3/4} \\]\n",
       "> \n",
       "> Solving for \\(z\\) and \\(y\\):\n",
       "> \\[ z = 2^{-5/12} \\]\n",
       "> \\[ y = 2^{-3/8} \\]\n",
       "> \n",
       "> Expressing \\(x\\), \\(y\\), and \\(z\\) in terms of powers of 2:\n",
       "> \\[ x = 2^{-7/24} \\]\n",
       "> \\[ y = 2^{-9/24} \\]\n",
       "> \\[ z = 2^{-10/24} \\]\n",
       "> \n",
       "> Calculating \\(x^4 y^3 z^2\\):\n",
       "> \\[ x^4 y^3 z^2 = (2^{-7/24})^4 \\cdot (2^{-9/24})^3 \\cdot (2^{-10/24})^2 \\]\n",
       "> \\[ = 2^{-28/24} \\cdot 2^{-27/24} \\cdot 2^{-20/24} \\]\n",
       "> \\[ = 2^{-65/24} \\]\n",
       "> \n",
       "> Thus, \\(\\log_2(x^4 y^3 z^2) = -65/24\\). Taking the absolute value, we get:\n",
       "> \\[ |\\log_2(x^4 y^3 z^2)| = \\frac{65}{24} \\]\n",
       "> \n",
       "> Since 65 and 24 are coprime, \\(m = 65\\) and \\(n = 24\\). Therefore, \\(m + n = 89\\).\n",
       "> \n",
       "> \\[\n",
       "> \\boxed{89}\n",
       "> \\]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6532d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing changing logprobs\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.8,\n",
    "    # repetition_penalty=1.1,\n",
    "    # frequency_penalty=0.1,\n",
    "    top_p = 0.9,\n",
    "    max_tokens = 10,\n",
    "    logprobs=2,\n",
    ")\n",
    "output = model.fast_generate(\n",
    "    [text],\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d535a910",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m system_prompt = \u001b[33mr\u001b[39m\u001b[33m'''\u001b[39m\u001b[33mAssume you are a professional mathematician.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33mPlease show your step by step reasoning in <think> tag. keep your \u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33msolution concise skipping arithmetic details, and generate your answer as \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[33m</answer>\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33m'''\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m prompt = system_prompt.format(\u001b[43mquestion\u001b[49m)\n\u001b[32m     16\u001b[39m text = tokenizer.apply_chat_template([\n\u001b[32m     17\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m : prompt},\n\u001b[32m     18\u001b[39m ], tokenize = \u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SamplingParams\n",
      "\u001b[31mNameError\u001b[39m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "system_prompt = r'''Assume you are a professional mathematician.{}\n",
    "Please show your step by step reasoning in <think> tag. keep your \n",
    "solution concise skipping arithmetic details, and generate your answer as \n",
    "a number in <answer> tag.\n",
    "Constraint: Please keep your response in the following format:\n",
    "<think>\n",
    "[your reasoning]\n",
    "</think>\n",
    "[your derivation, keep this short] \n",
    "<answer>\n",
    "[succinct answer]\n",
    "</answer>\n",
    "'''\n",
    "prompt = system_prompt.format(question)\n",
    "\n",
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"user\", \"content\" : prompt},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.5,\n",
    "    repetition_penalty=1.1,\n",
    "    # frequency_penalty=0.1,\n",
    "    top_p = 0.9,\n",
    "    max_tokens = 40000,\n",
    "\n",
    ")\n",
    "output = model.fast_generate(\n",
    "    [text],\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = None,\n",
    ")[0].outputs[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d21ac56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Okay, so I have this problem here with three logarithmic equations involving variables x, y, and z. The goal is to find the absolute value of log base 2 of (x⁴y³z²), which will give me a fraction m/n where m and n are coprime positive integers. Then, I need to add m and n together for the final answer.\n",
       "> \n",
       "> First, let's write down the given equations:\n",
       "> \n",
       "> 1. log₂(x / yz) = 1/2\n",
       "> 2. log₂(y / xz) = 1/3\n",
       "> 3. log₂(z / xy) = 1/4\n",
       "> \n",
       "> I remember that logarithms can be converted into exponential form to make them easier to work with. So, if log₂(A) = B, then A = 2^B. Let me apply that to each equation.\n",
       "> \n",
       "> Starting with the first equation:\n",
       "> log₂(x / yz) = 1/2  \n",
       "> This means that x / yz = 2^(1/2)  \n",
       "> Which simplifies to x = yz * sqrt(2)\n",
       "> \n",
       "> Second equation:\n",
       "> log₂(y / xz) = 1/3  \n",
       "> So, y / xz = 2^(1/3)  \n",
       "> Thus, y = xz * 2^(1/3)\n",
       "> \n",
       "> Third equation:\n",
       "> log₂(z / xy) = 1/4  \n",
       "> Therefore, z / xy = 2^(1/4)  \n",
       "> Hence, z = xy * 2^(1/4)\n",
       "> \n",
       "> Now, I have expressions connecting x, y, and z. It seems like substitution might help here. Let me see if I can express all variables in terms of one variable or relate them in some way.\n",
       "> \n",
       "> Looking at the first equation, x = yz * sqrt(2). From the second equation, y = xz * 2^(1/3). If I substitute x from the first equation into the second, maybe I can get an expression for y in terms of z.\n",
       "> \n",
       "> Substituting x:\n",
       "> y = (yz * sqrt(2)) * z * 2^(1/3)\n",
       "> Simplify:\n",
       "> y = yz² * sqrt(2) * 2^(1/3)\n",
       "> \n",
       "> Divide both sides by y (assuming y ≠ 0):\n",
       "> 1 = z² * sqrt(2) * 2^(1/3)\n",
       "> \n",
       "> Let me compute sqrt(2) * 2^(1/3). Since sqrt(2) is 2^(1/2), multiplying it by 2^(1/3) gives 2^(1/2 + 1/3) = 2^(5/6).\n",
       "> \n",
       "> So,\n",
       "> 1 = z² * 2^(5/6)\n",
       "> \n",
       "> Therefore,\n",
       "> z² = 2^(-5/6)\n",
       "> \n",
       "> Taking square roots on both sides:\n",
       "> z = 2^(-5/12)\n",
       "> \n",
       "> Since z is positive, we don't consider the negative root.\n",
       "> \n",
       "> Similarly, now that I have z, perhaps I can find y and x.\n",
       "> \n",
       "> From the first equation, x = yz * sqrt(2). Plugging z = 2^(-5/12):\n",
       "> \n",
       "> x = y * 2^(-5/12) * 2^(1/2)\n",
       "> Combine exponents:\n",
       "> x = y * 2^(-5/12 + 6/12) = y * 2^(1/12)\n",
       "> \n",
       "> From the third equation, z = xy * 2^(1/4). Plug in z and x in terms of y:\n",
       "> \n",
       "> 2^(-5/12) = (y * 2^(1/12)) * y * 2^(1/4)\n",
       "> Simplify RHS:\n",
       "> = y² * 2^(1/12 + 1/4) = y² * 2^(1/12 + 3/12) = y² * 2^(4/12) = y² * 2^(1/3)\n",
       "> \n",
       "> Thus,\n",
       "> 2^(-5/12) = y² * 2^(1/3)\n",
       "> \n",
       "> Divide both sides by 2^(1/3):\n",
       "> y² = 2^(-5/12 - 1/3) = 2^(-5/12 - 4/12) = 2^(-9/12) = 2^(-3/4)\n",
       "> \n",
       "> Take square root:\n",
       "> y = 2^(-3/8)\n",
       "> \n",
       "> Again, since y is positive.\n",
       "> \n",
       "> Now, having found y, x, z in terms of powers of 2:\n",
       "> \n",
       "> x = y * 2^(1/12) = [2^(-3/8)] * 2^(1/12) = 2^(-3/8 + 1/12)\n",
       "> Find common denominator for exponents:\n",
       "> -3/8 = -9/24, 1/12 = 2/24, so total exponent is (-9 + 2)/24 = -7/24\n",
       "> Thus, x = 2^(-7/24)\n",
       "> \n",
       "> Similarly, z = 2^(-5/12) = 2^(-10/24) = 2^(-5/12)\n",
       "> \n",
       "> And y = 2^(-3/8) = 2^(-9/24)\n",
       "> \n",
       "> Now, I need to compute |log₂(x⁴y³z²)|.\n",
       "> \n",
       "> Compute each term inside the log:\n",
       "> \n",
       "> x⁴ = [2^(-7/24)]⁴ = 2^(-28/24) = 2^(-7/6)\n",
       "> y³ = [2^(-9/24)]³ = 2^(-27/24) = 2^(-9/8)\n",
       "> z² = [2^(-10/24)]² = 2^(-20/24) = 2^(-5/6)\n",
       "> \n",
       "> Multiply these together:\n",
       "> x⁴y³z² = 2^(-7/6) * 2^(-9/8) * 2^(-5/6) = 2^(-7/6 -9/8 -5/6)\n",
       "> \n",
       "> Compute the sum of exponents:\n",
       "> \n",
       "> Convert all to 24 denominators:\n",
       "> -7/6 = -28/24\n",
       "> -9/8 = -27/24\n",
       "> -5/6 = -20/24\n",
       "> \n",
       "> Total exponent: -28/24 -27/24 -20/24 = (-28 -27 -20)/24 = (-75)/24 = -25/8\n",
       "> \n",
       "> Thus, x⁴y³z² = 2^(-25/8)\n",
       "> \n",
       "> Now, take log base 2:\n",
       "> log₂(x⁴y³z²) = log₂(2^(-25/8)) = -25/8\n",
       "> \n",
       "> The absolute value is |-25/8| = 25/8.\n",
       "> \n",
       "> So, m = 25, n = 8. They are coprime. Therefore, m + n = 25 + 8 = 33.\n",
       "> \n",
       "> **Final Answer**\n",
       "> \\boxed{33}\n",
       "> </think>\n",
       "> \n",
       "> Given the system of equations involving logarithms:\n",
       "> \n",
       "> 1. \\(\\log_2\\left(\\frac{x}{yz}\\right) = \\frac{1}{2}\\)\n",
       "> 2. \\(\\log_2\\left(\\frac{y}{xz}\\right) = \\frac{1}{3}\\)\n",
       "> 3. \\(\\log_2\\left(\\frac{z}{xy}\\right) = \\frac{1}{4}\\)\n",
       "> \n",
       "> We convert these logarithmic equations into exponential form:\n",
       "> \n",
       "> 1. \\(x = yz \\cdot \\sqrt{2}\\)\n",
       "> 2. \\(y = xz \\cdot 2^{1/3}\\)\n",
       "> 3. \\(z = xy \\cdot 2^{1/4}\\)\n",
       "> \n",
       "> Next, we express each variable in terms of another:\n",
       "> \n",
       "> From the first equation, substituting \\(x\\) from the second equation:\n",
       "> \\[ y = (yz \\cdot \\sqrt{2}) \\cdot z \\cdot 2^{1/3} \\]\n",
       "> \\[ y = yz^2 \\cdot 2^{5/6} \\]\n",
       "> \\[ 1 = z^2 \\cdot 2^{5/6} \\]\n",
       "> \\[ z = 2^{-5/12} \\]\n",
       "> \n",
       "> Using \\(z = 2^{-5/12}\\) in the first equation:\n",
       "> \\[ x = y \\cdot 2^{-5/12} \\cdot \\sqrt{2} \\]\n",
       "> \\[ x = y \\cdot 2^{1/12} \\]\n",
       "> \n",
       "> From the third equation:\n",
       "> \\[ z = xy \\cdot 2^{1/4} \\]\n",
       "> \\[ 2^{-5/12} = (y \\cdot 2^{1/12}) \\cdot y \\cdot 2^{1/4} \\]\n",
       "> \\[ 2^{-5/12} = y^2 \\cdot 2^{1/3} \\]\n",
       "> \\[ y = 2^{-3/8} \\]\n",
       "> \n",
       "> Expressing \\(x\\) and \\(y\\) in terms of \\(z\\):\n",
       "> \\[ x = 2^{-7/24} \\]\n",
       "> \\[ y = 2^{-9/24} \\]\n",
       "> \\[ z = 2^{-10/24} \\]\n",
       "> \n",
       "> To find \\(\\left|\\log_2(x^4y^3z^2)\\right|\\):\n",
       "> \n",
       "> Calculate each term:\n",
       "> \\[ x^4 = 2^{-28/24} \\]\n",
       "> \\[ y^3 = 2^{-27/24} \\]\n",
       "> \\[ z^2 = 2^{-20/24} \\]\n",
       "> \n",
       "> Combine these:\n",
       "> \\[ x^4y^3z^2 = 2^{-28/24 - 27/24 - 20/24} = 2^{-75/24} = 2^{-25/8} \\]\n",
       "> \n",
       "> Taking the logarithm:\n",
       "> \\[ \\log_2(x^4y^3z^2) = -25/8 \\]\n",
       "> \n",
       "> Taking the absolute value:\n",
       "> \\[ \\left|\\log_2(x^4y^3z^2)\\right| = 25/8 \\]\n",
       "> \n",
       "> Thus, \\(m = 25\\) and \\(n = 8\\), giving \\(m + n = 33\\).\n",
       "> \n",
       "> \\[\n",
       "> \\boxed{33}\n",
       "> \\]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65ff5d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_apply',\n",
       " '_assisted_decoding',\n",
       " '_autoset_attn_implementation',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_beam_search',\n",
       " '_call_impl',\n",
       " '_check_and_enable_flash_attn_2',\n",
       " '_check_and_enable_flex_attn',\n",
       " '_check_and_enable_sdpa',\n",
       " '_constrained_beam_search',\n",
       " '_contrastive_search',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_copy_lm_head_original_to_resized',\n",
       " '_create_repo',\n",
       " '_dispatch_accelerate_model',\n",
       " '_dola_decoding',\n",
       " '_expand_inputs_for_generation',\n",
       " '_fix_state_dict_key_on_load',\n",
       " '_fix_state_dict_key_on_save',\n",
       " '_fix_state_dict_keys_on_load',\n",
       " '_fix_state_dict_keys_on_save',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_cache',\n",
       " '_get_candidate_generator',\n",
       " '_get_files_timestamps',\n",
       " '_get_initial_cache_position',\n",
       " '_get_logits_processor',\n",
       " '_get_name',\n",
       " '_get_no_split_modules',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_group_beam_search',\n",
       " '_has_unfinished_sequences',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_added_embeddings_weights_with_mean',\n",
       " '_init_added_lm_head_bias_with_mean',\n",
       " '_init_added_lm_head_weights_with_mean',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_named_members',\n",
       " '_old_generate',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_cache_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_generated_length',\n",
       " '_prepare_generation_config',\n",
       " '_prepare_model_inputs',\n",
       " '_prepare_special_tokens',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_sample',\n",
       " '_save_to_state_dict',\n",
       " '_saved_temp_tokenizer',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_slow_forward',\n",
       " '_supports_default_dynamic_cache',\n",
       " '_supports_logits_to_keep',\n",
       " '_temporary_reorder_cache',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_assistant',\n",
       " '_validate_generated_length',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_wrapped_call_impl',\n",
       " 'active_adapter',\n",
       " 'active_adapters',\n",
       " 'add_adapter',\n",
       " 'add_memory_hooks',\n",
       " 'add_model_tags',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'can_generate',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'compute_transition_scores',\n",
       " 'config_class',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'delete_adapter',\n",
       " 'dequantize',\n",
       " 'disable_adapters',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'enable_adapters',\n",
       " 'enable_input_require_grads',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fast_generate',\n",
       " 'fast_generate_batches',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generate',\n",
       " 'get_adapter_state_dict',\n",
       " 'get_buffer',\n",
       " 'get_compiled_call',\n",
       " 'get_decoder',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'half',\n",
       " 'heal_tokens',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_backend_compatible',\n",
       " 'lm_head',\n",
       " 'load_adapter',\n",
       " 'load_state_dict',\n",
       " 'loss_function',\n",
       " 'model',\n",
       " 'modules',\n",
       " 'mtia',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'original_push_to_hub',\n",
       " 'parameters',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'push_to_hub',\n",
       " 'push_to_hub_ggml',\n",
       " 'push_to_hub_gguf',\n",
       " 'push_to_hub_merged',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_load_state_dict_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_post_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'reverse_bettertransformer',\n",
       " 'save_pretrained',\n",
       " 'save_pretrained_ggml',\n",
       " 'save_pretrained_gguf',\n",
       " 'save_pretrained_merged',\n",
       " 'set_adapter',\n",
       " 'set_decoder',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'set_output_embeddings',\n",
       " 'set_submodule',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'tensor_parallel',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to_bettertransformer',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'type',\n",
       " 'warn_if_padding_and_no_attention_mask',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[method_name for method_name in dir(model) if callable(getattr(model, method_name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b2d2642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Okay, so I have this problem here where I need to find the absolute value of log base 2 of (x⁴y³z²). The problem gives me three equations involving logarithms with base 2, and it involves x, y, z, which are positive real numbers. Let me try to figure this out step by step.\n",
       "> \n",
       "> First, let me write down the equations:\n",
       "> \n",
       "> 1. log₂(x / (y z)) = 1/2\n",
       "> 2. log₂(y / (x z)) = 1/3\n",
       "> 3. log₂(z / (x y)) = 1/4\n",
       "> \n",
       "> Hmm, so each equation is a logarithm of a fraction where one variable is in the numerator and the product of the other two is in the denominator. Maybe I can rewrite these using logarithm properties to separate the variables. \n",
       "> \n",
       "> I remember that log₂(a/b) = log₂a - log₂b, so maybe I can apply that here.\n",
       "> \n",
       "> Let me rewrite each equation:\n",
       "> \n",
       "> 1. log₂x - log₂(y z) = 1/2\n",
       "> 2. log₂y - log₂(x z) = 1/3\n",
       "> 3. log₂z - log₂(x y) = 1/4\n",
       "> \n",
       "> Now, I can further break down the logs in the denominators using log₂(ab) = log₂a + log₂b.\n",
       "> \n",
       "> So, applying that:\n",
       "> \n",
       "> 1. log₂x - (log₂y + log₂z) = 1/2\n",
       "> 2. log₂y - (log₂x + log₂z) = 1/3\n",
       "> 3. log₂z - (log₂x + log₂y) = 1/4\n",
       "> \n",
       "> Let me denote log₂x = a, log₂y = b, and log₂z = c. That might make it easier to handle. So now, I can rewrite the equations in terms of a, b, c.\n",
       "> \n",
       "> 1. a - (b + c) = 1/2\n",
       "> 2. b - (a + c) = 1/3\n",
       "> 3. c - (a + b) = 1/4\n",
       "> \n",
       "> Okay, so now I have a system of three linear equations:\n",
       "> \n",
       "> 1. a - b - c = 1/2\n",
       "> 2. -a + b - c = 1/3\n",
       "> 3. -a - b + c = 1/4\n",
       "> \n",
       "> Hmm, this is a system of three equations with three variables: a, b, c. I can solve this system to find a, b, c, and then use them to find log₂(x⁴y³z²), which is 4a + 3b + 2c.\n",
       "> \n",
       "> Let me write down the equations:\n",
       "> \n",
       "> Equation 1: a - b - c = 1/2\n",
       "> \n",
       "> Equation 2: -a + b - c = 1/3\n",
       "> \n",
       "> Equation 3: -a - b + c = 1/4\n",
       "> \n",
       "> Hmm, solving this system. Let me try adding them up or manipulating them to eliminate variables.\n",
       "> \n",
       "> First, let me add all three equations together:\n",
       "> \n",
       "> Equation 1 + Equation 2 + Equation 3:\n",
       "> \n",
       "> (a - b - c) + (-a + b - c) + (-a - b + c) = 1/2 + 1/3 + 1/4\n",
       "> \n",
       "> Let me compute the left side:\n",
       "> \n",
       "> a - b - c - a + b - c - a - b + c\n",
       "> \n",
       "> Simplify term by term:\n",
       "> \n",
       "> a - a - a = -a\n",
       "> \n",
       "> -b + b - b = -b\n",
       "> \n",
       "> -c - c + c = -c\n",
       "> \n",
       "> So overall, -a - b - c\n",
       "> \n",
       "> Right side:\n",
       "> \n",
       "> 1/2 + 1/3 + 1/4\n",
       "> \n",
       "> Let me compute that. Let me find a common denominator. The least common denominator for 2,3,4 is 12.\n",
       "> \n",
       "> So:\n",
       "> \n",
       "> 1/2 = 6/12\n",
       "> \n",
       "> 1/3 = 4/12\n",
       "> \n",
       "> 1/4 = 3/12\n",
       "> \n",
       "> Adding them: 6/12 + 4/12 + 3/12 = 13/12\n",
       "> \n",
       "> So, we have:\n",
       "> \n",
       "> - (a + b + c) = 13/12\n",
       "> \n",
       "> Which implies:\n",
       "> \n",
       "> a + b + c = -13/12\n",
       "> \n",
       "> Wait, but a, b, c are log₂x, log₂y, log₂z, which are logs of positive real numbers, so they should be positive. But here, a + b + c is negative? That seems contradictory. Maybe I made a mistake in adding.\n",
       "> \n",
       "> Wait, let me check the addition:\n",
       "> \n",
       "> Equation 1: a - b - c = 1/2\n",
       "> \n",
       "> Equation 2: -a + b - c = 1/3\n",
       "> \n",
       "> Equation 3: -a - b + c = 1/4\n",
       "> \n",
       "> Adding them:\n",
       "> \n",
       "> a - b - c - a + b - c - a - b + c\n",
       "> \n",
       "> So for a: 1 -1 -1 = -1\n",
       "> \n",
       "> For b: -1 +1 -1 = -1\n",
       "> \n",
       "> For c: -1 -1 +1 = -1\n",
       "> \n",
       "> So total: -a - b - c = 13/12\n",
       "> \n",
       "> Thus, a + b + c = -13/12\n",
       "> \n",
       "> But that's negative, but a, b, c are positive since they are logs of positive numbers.\n",
       "> \n",
       "> Hmm, that suggests something is wrong. Did I add correctly?\n",
       "> \n",
       "> Wait, maybe I should try solving the system step by step instead of adding all three.\n",
       "> \n",
       "> Let me write the equations again:\n",
       "> \n",
       "> 1. a - b - c = 1/2\n",
       "> \n",
       "> 2. -a + b - c = 1/3\n",
       "> \n",
       "> 3. -a - b + c = 1/4\n",
       "> \n",
       "> Let me label them as Eq1, Eq2, Eq3.\n",
       "> \n",
       "> Maybe I can subtract Eq1 from Eq2.\n",
       "> \n",
       "> Wait, actually, let me try solving step by step.\n",
       "> \n",
       "> First, let's consider Eq1 and Eq2.\n",
       "> \n",
       "> From Eq1: a - b - c = 1/2\n",
       "> \n",
       "> From Eq2: -a + b - c = 1/3\n",
       "> \n",
       "> Let me add Eq1 and Eq2 to eliminate a:\n",
       "> \n",
       "> (a - b - c) + (-a + b - c) = 1/2 + 1/3\n",
       "> \n",
       "> Simplify:\n",
       "> \n",
       "> a - b - c - a + b - c = 1/2 + 1/3\n",
       "> \n",
       "> Which is: (-b + b) + (-c - c) = 1/2 + 1/3\n",
       "> \n",
       "> So, 0 - 2c = 1/2 + 1/3\n",
       "> \n",
       "> Wait, 1/2 + 1/3 is 5/6. So:\n",
       "> \n",
       "> -2c = 5/6\n",
       "> \n",
       "> Thus, c = (-5/6)/2 = -5/12\n",
       "> \n",
       "> Wait, c is log₂z, which is a log of a positive number, so c must be positive. So c = -5/12? That's negative. That can't be right. I must have messed up something.\n",
       "> \n",
       "> Wait, maybe I should try subtracting equations differently. Let's see.\n",
       "> \n",
       "> Wait, perhaps I made a mistake in adding Eq1 and Eq2. Let me try it again.\n",
       "> \n",
       "> From Eq1: a - b - c = 1/2\n",
       "> \n",
       "> From Eq2: -a + b - c = 1/3\n",
       "> \n",
       "> Adding them:\n",
       "> \n",
       "> a - b - c - a + b - c = 1/2 + 1/3\n",
       "> \n",
       "> Wait, that's still:\n",
       "> \n",
       "> a - a = 0\n",
       "> \n",
       "> -b + b = 0\n",
       "> \n",
       "> -c - c = -2c\n",
       "> \n",
       "> Right side: 1/2 + 1/3 = 5/6\n",
       "> \n",
       "> So, -2c = 5/6 => c = -5/12\n",
       "> \n",
       "> Same result. Hmm. Negative c. But c is log₂z, which is positive. So, that's impossible. Therefore, maybe I have a mistake in adding the equations.\n",
       "> \n",
       "> Wait, no. Actually, in the original step, when I added Eq1, Eq2, and Eq3, I think I did that correctly, but when adding the first two equations, maybe I made an error.\n",
       "> \n",
       "> Wait, let's re-examine the addition:\n",
       "> \n",
       "> Eq1: a - b - c = 1/2\n",
       "> \n",
       "> Eq2: -a + b - c = 1/3\n",
       "> \n",
       "> Adding them:\n",
       "> \n",
       "> a - b - c - a + b - c = 1/2 + 1/3\n",
       "> \n",
       "> Simplify:\n",
       "> \n",
       "> 0a + 0b - 2c = 5/6\n",
       "> \n",
       "> So, -2c = 5/6 => c = -5/12. So, same result.\n",
       "> \n",
       "> Hmm, this suggests that perhaps the system is inconsistent? Or perhaps I have an error in setting up the equations.\n",
       "> \n",
       "> Wait, let me go back.\n",
       "> \n",
       "> Original equations:\n",
       "> \n",
       "> 1. log₂(x / (y z)) = 1/2 => log₂x - log₂y - log₂z = 1/2\n",
       "> \n",
       "> 2. log₂(y / (x z)) = 1/3 => log₂y - log₂x - log₂z = 1/3\n",
       "> \n",
       "> 3. log₂(z / (x y)) = 1/4 => log₂z - log₂x - log₂y = 1/4\n",
       "> \n",
       "> So, that's correct. So, the three equations are:\n",
       "> \n",
       "> 1. a - b - c = 1/2\n",
       "> \n",
       "> 2. -a + b - c = 1/3\n",
       "> \n",
       "> 3. -a - b + c = 1/4\n",
       "> \n",
       "> So, yeah, it's correct. So, when I added them, I got c = -5/12, which is negative, but that can't be. So, maybe the system is inconsistent, but the problem states that such x, y, z exist. So, something must be wrong in my approach.\n",
       "> \n",
       "> Wait, another thought. Maybe I should subtract the equations instead of adding them. Let me try subtracting.\n",
       "> \n",
       "> Let me subtract Eq1 and Eq2.\n",
       "> \n",
       "> Wait, no, let's try a different approach.\n",
       "> \n",
       "> Let me write the three equations:\n",
       "> \n",
       "> 1. a - b - c = 1/2\n",
       "> \n",
       "> 2. -a + b - c = 1/3\n",
       "> \n",
       "> 3. -a - b + c = 1/4\n",
       "> \n",
       "> Let me try solving for a, b, c.\n",
       "> \n",
       "> Let me denote:\n",
       "> \n",
       "> From Eq1: a = 1/2 + b + c\n",
       "> \n",
       "> From Eq2: -a + b - c = 1/3\n",
       "> \n",
       "> Substitute a from Eq1 into Eq2:\n",
       "> \n",
       "> -(1/2 + b + c) + b - c = 1/3\n",
       "> \n",
       "> Simplify:\n",
       "> \n",
       "> -1/2 - b - c + b - c = 1/3\n",
       "> \n",
       "> Which simplifies to:\n",
       "> \n",
       "> -1/2 -2c = 1/3\n",
       "> \n",
       "> So, -2c = 1/3 + 1/2 = (2 + 3)/6 = 5/6\n",
       "> \n",
       "> Thus, c = -5/12\n",
       "> \n",
       "> Same as before. Hmm. That's negative.\n",
       "> \n",
       "> Wait, maybe let's try solving another pair.\n",
       "> \n",
       "> Let me subtract Eq2 from Eq1.\n",
       "> \n",
       "> Wait, Eq1: a - b - c = 1/2\n",
       "> \n",
       "> Eq2: -a + b - c = 1/3\n",
       "> \n",
       "> If I add Eq1 and Eq2, as I did before, I get c = -5/12. So, same result.\n",
       "> \n",
       "> Alternatively, if I consider adding Eq1 and Eq3:\n",
       "> \n",
       "> Eq1: a - b - c = 1/2\n",
       "> \n",
       "> Eq3: -a - b + c = 1/4\n",
       "> \n",
       "> Adding them:\n",
       "> \n",
       "> a - b - c - a - b + c = 1/2 + 1/4\n",
       "> \n",
       "> Simplify:\n",
       "> \n",
       "> (-2b) = 3/4\n",
       "> \n",
       "> Thus, b = (-3/4)/2 = -3/8\n",
       "> \n",
       "> Wait, that can't be because b = log₂y, which must be positive. So, b = -3/8. Negative. That's a problem.\n",
       "> \n",
       "> Wait, so perhaps my approach is wrong.\n",
       "> \n",
       "> Wait, maybe I should consider that maybe I made a mistake in the equation setup.\n",
       "> \n",
       "> Let me go back.\n",
       "> \n",
       "> Original equations:\n",
       "> \n",
       "> 1. log₂(x / (y z)) = 1/2\n",
       "> \n",
       "> So, that is log₂x - log₂y - log₂z = 1/2\n",
       "> \n",
       "> Which is a - b - c = 1/2\n",
       "> \n",
       "> Similarly, equation 2: log₂y - log₂x - log₂z = 1/3 => -a + b - c = 1/3\n",
       "> \n",
       "> Equation 3: log₂z - log₂x - log₂y = 1/4 => -a - b + c = 1/4\n",
       "> \n",
       "> So that's correct.\n",
       "> \n",
       "> Wait, but when I add all three equations, I get a + b + c = -13/12, which is negative. But a, b, c are positive. So, seems impossible.\n",
       "> \n",
       "> But in the problem statement, it says that x, y, z are positive real numbers that satisfy the system. So, this suggests that the system is consistent, but when solving, we get negative values.\n",
       "> \n",
       "> Wait, but perhaps the error is in assuming that all variables are positive. Let me check the original logarithms:\n",
       "> \n",
       "> log₂(x / (y z)) = 1/2\n",
       "> \n",
       "> Since x, y, z are positive, the argument of the logarithm is positive, so this is okay.\n",
       "> \n",
       "> But, if x, y, z are positive, but the system when solving seems to require a + b + c negative. Maybe I need to think differently.\n",
       "> \n",
       "> Wait, perhaps instead of solving the system as equations for a, b, c, maybe it's better to express the ratios.\n",
       "> \n",
       "> Wait, another approach: Let me denote u = log₂x, v = log₂y, w = log₂z.\n",
       "> \n",
       "> Then the system becomes:\n",
       "> \n",
       "> 1. u - v - w = 1/2\n",
       "> \n",
       "> 2. -u + v - w = 1/3\n",
       "> \n",
       "> 3. -u - v + w = 1/4\n",
       "> \n",
       "> So, it's the same as before. So, same problem.\n",
       "> \n",
       "> Wait, perhaps I can write the system as:\n",
       "> \n",
       "> 1. u - v - w = 1/2\n",
       "> \n",
       "> 2. -u + v - w = 1/3\n",
       "> \n",
       "> 3. -u - v + w = 1/4\n",
       "> \n",
       "> So, adding the three equations:\n",
       "> \n",
       "> (1 + 2 + 3): (-u - v - w) - (u + v + w) = (1/2 + 1/3 + 1/4)\n",
       "> \n",
       "> Wait, no, better:\n",
       "> \n",
       "> Wait, let me think. If I have:\n",
       "> \n",
       "> Equation1: u - v - w = 1/2\n",
       "> \n",
       "> Equation2: -u + v - w = 1/3\n",
       "> \n",
       "> Equation3: -u - v + w = 1/4\n",
       "> \n",
       "> Let me denote them as Eq1, Eq2, Eq3.\n",
       "> \n",
       "> Now, let me try to solve for u, v, w.\n",
       "> \n",
       "> Let me write the equations:\n",
       "> \n",
       "> From Eq1: u = v + w + 1/2\n",
       "> \n",
       "> From Eq2: -u + v - w = 1/3 => u = -v + w + 1/3\n",
       "> \n",
       "> From Eq3: -u - v + w = 1/4 => u = -v + w - 1/4\n",
       "> \n",
       "> Wait, now we have three expressions for u:\n",
       "> \n",
       "> 1. From Eq1: u = v + w + 1/2\n",
       "> \n",
       "> 2. From Eq2: u = -v + w + 1/3\n",
       "> \n",
       "> 3. From Eq3: u = -v + w - 1/4\n",
       "> \n",
       "> So, since all equal to u, set them equal to each other.\n",
       "> \n",
       "> From 1 and 2:\n",
       "> \n",
       "> v + w + 1/2 = -v + w + 1/3\n",
       "> \n",
       "> Simplify:\n",
       "> \n",
       "> v + w + 1/2 = -v + w + 1/3\n",
       "> \n",
       "> Subtract w from both sides:\n",
       "> \n",
       "> v + 1/2 = -v + 1/3\n",
       "> \n",
       "> Bring -v to left:\n",
       "> \n",
       "> v + v + 1/2 = 1/3\n",
       "> \n",
       "> 2v = 1/3 - 1/2\n",
       "> \n",
       "> Compute 1/3 - 1/2: that's -1/6\n",
       "> \n",
       "> So, 2v = -1/6 => v = -1/12\n",
       "> \n",
       "> But v = log₂y, which is supposed to be positive. But v = -1/12. That's negative, which is impossible.\n",
       "> \n",
       "> Wait, that's the same problem as before. So, same result.\n",
       "> \n",
       "> Hmm, this suggests that the system is inconsistent? But the problem states that such x, y, z exist. So, maybe I made a mistake in the setup.\n",
       "> \n",
       "> Wait, let me double-check the original problem:\n",
       "> \n",
       "> \"Assume you are a professional mathematician. Let x, y and z be positive real numbers that satisfy the following system of equations:\n",
       "> \n",
       "> log₂(x / yz) = 1/2\n",
       "> \n",
       "> log₂(y / xz) = 1/3\n",
       "> \n",
       "> log₂(z / xy) = 1/4\n",
       "> \n",
       "> Then the value of |log₂(x⁴y³z²)| is m/n where m and n are relatively prime positive integers. Find m + n.\"\n",
       "> \n",
       "> So, that's correct.\n",
       "> \n",
       "> Wait, but if solving gives a negative value, perhaps I need to check if there's a mistake in the way I set up the equations.\n",
       "> \n",
       "> Wait, another approach: Let's express all logs in terms of log₂x, log₂y, log₂z.\n",
       "> \n",
       "> Let me denote u = log₂x, v = log₂y, w = log₂z.\n",
       "> \n",
       "> Then,\n",
       "> \n",
       "> log₂(x / y z) = u - v - w = 1/2\n",
       "> \n",
       "> log₂(y / x z) = v - u - w = 1/3\n",
       "> \n",
       "> log₂(z / x y) = w - u - v = 1/4\n",
       "> \n",
       "> So, equations:\n",
       "> \n",
       "> 1. u - v - w = 1/2\n",
       "> \n",
       "> 2. -u + v - w = 1/3\n",
       "> \n",
       "> 3. -u - v + w = 1/4\n",
       "> \n",
       "> Let me write them as:\n",
       "> \n",
       "> 1. u - v - w = 1/2\n",
       "> \n",
       "> 2. -u + v - w = 1/3\n",
       "> \n",
       "> 3. -u - v + w"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99b7a69d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'RequestOutput' object cannot be converted to 'Sequence'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m to_markdown(\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.replace(prompt, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3860\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.decode\u001b[39m\u001b[34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[39m\n\u001b[32m   3857\u001b[39m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[32m   3858\u001b[39m token_ids = to_py_obj(token_ids)\n\u001b[32m-> \u001b[39m\u001b[32m3860\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3863\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3864\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3865\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_env/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:668\u001b[39m, in \u001b[36mPreTrainedTokenizerFast._decode\u001b[39m\u001b[34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m    667\u001b[39m     token_ids = [token_ids]\n\u001b[32m--> \u001b[39m\u001b[32m668\u001b[39m text = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m clean_up_tokenization_spaces = (\n\u001b[32m    671\u001b[39m     clean_up_tokenization_spaces\n\u001b[32m    672\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.clean_up_tokenization_spaces\n\u001b[32m    674\u001b[39m )\n\u001b[32m    675\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[31mTypeError\u001b[39m: argument 'ids': 'RequestOutput' object cannot be converted to 'Sequence'"
     ]
    }
   ],
   "source": [
    "to_markdown(tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "469f4ff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Make sure that a `_reorder_cache` function is correctly implemented in transformers.models.qwen2.modeling_qwen2 to enable beam search for <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m inputs = tokenizer(prompt, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(model.device)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Generate with nucleus sampling (top-p sampling)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenormalize_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# If multiple samples, use majority vote (here we simply pick the first for raw eval)\u001b[39;00m\n\u001b[32m     26\u001b[39m generated_text = tokenizer.decode(outputs[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_env/lib/python3.11/site-packages/unsloth/models/llama.py:1578\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1576\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1577\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1578\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1579\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1581\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1582\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1583\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1584\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_env/lib/python3.11/site-packages/transformers/generation/utils.py:2254\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[39m\n\u001b[32m   2246\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2247\u001b[39m         input_ids=input_ids,\n\u001b[32m   2248\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2249\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2250\u001b[39m         **model_kwargs,\n\u001b[32m   2251\u001b[39m     )\n\u001b[32m   2253\u001b[39m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2254\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2255\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2260\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2261\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2262\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2264\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n\u001b[32m   2265\u001b[39m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[32m   2266\u001b[39m     beam_scorer = BeamSearchScorer(\n\u001b[32m   2267\u001b[39m         batch_size=batch_size,\n\u001b[32m   2268\u001b[39m         num_beams=generation_config.num_beams,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2274\u001b[39m         max_length=generation_config.max_length,\n\u001b[32m   2275\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_env/lib/python3.11/site-packages/transformers/generation/utils.py:3555\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3552\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m outputs\n\u001b[32m   3554\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3555\u001b[39m     model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_temporary_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3556\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpast_key_values\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\n\u001b[32m   3557\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_scores:\n\u001b[32m   3560\u001b[39m     beam_indices = \u001b[38;5;28mtuple\u001b[39m((beam_indices[beam_idx[i]] + (beam_idx[i],) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(beam_indices))))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_env/lib/python3.11/site-packages/transformers/generation/utils.py:3316\u001b[39m, in \u001b[36mGenerationMixin._temporary_reorder_cache\u001b[39m\u001b[34m(self, past_key_values, beam_idx)\u001b[39m\n\u001b[32m   3314\u001b[39m \u001b[38;5;66;03m# Exception 1: code path for models using the legacy cache format\u001b[39;00m\n\u001b[32m   3315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m-> \u001b[39m\u001b[32m3316\u001b[39m     past_key_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3317\u001b[39m \u001b[38;5;66;03m# Exception 2: models with different cache formats. These are limited to `DynamicCache` until their\u001b[39;00m\n\u001b[32m   3318\u001b[39m \u001b[38;5;66;03m# cache format is standardized, to avoid adding complexity to the codebase.\u001b[39;00m\n\u001b[32m   3319\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgptbigcode\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_class:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_env/lib/python3.11/site-packages/transformers/generation/utils.py:819\u001b[39m, in \u001b[36mGenerationMixin._reorder_cache\u001b[39m\u001b[34m(self, past_key_values, beam_idx)\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_reorder_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m, past_key_values, beam_idx):\n\u001b[32m--> \u001b[39m\u001b[32m819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    820\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMake sure that a `_reorder_cache` function is correctly implemented in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    821\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m enable beam search for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    822\u001b[39m     )\n",
      "\u001b[31mNotImplementedError\u001b[39m: Make sure that a `_reorder_cache` function is correctly implemented in transformers.models.qwen2.modeling_qwen2 to enable beam search for <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>"
     ]
    }
   ],
   "source": [
    "# system_prompt = r'''Assume you are a professional mathematician.{}\\n\n",
    "# Please generate your answer as a number in <answer> tag.\\n'''\n",
    "\n",
    "system_prompt = r'''Assume you are a professional mathematician.{}\n",
    "Please show your step by step reasoning in <thinking> tag, keep your \n",
    "solution concise skipping arithmetic details, and generate your answer as \n",
    "a number in <answer> tag.'''\n",
    "prompt = system_prompt.format(question)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate with nucleus sampling (top-p sampling)\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=True,\n",
    "    top_p=0.9, \n",
    "    temperature=1.0,\n",
    "    num_return_sequences=10,\n",
    "    num_beams=10,\n",
    "    repetition_penalty=1.2,\n",
    "    length_penalty=0,\n",
    "    renormalize_logits=True\n",
    ")\n",
    "\n",
    "# If multiple samples, use majority vote (here we simply pick the first for raw eval)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6504cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "\n",
    "\n",
    "# system_prompt = r'''Assume you are a professional mathematician.{}\\n\n",
    "# Please show your step by step reasoning in <thinking> tag, keep your solution concise skipping arithmetic details, and generate your answer as a number in <answer> tag.\\n'''\n",
    "system_prompt = r'''Assume you are a professional mathematician.{}\n",
    "Please generate your answer as a number in <answer> tag.\n",
    "'''\n",
    "prompt = system_prompt.format(question)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, \n",
    "                        #  streamer = text_streamer, \n",
    "                         max_new_tokens = 2048)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad0feb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> \n",
       "> \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a74f8",
   "metadata": {},
   "source": [
    "#### transformers experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1f3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "# Configure 4-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80aa2188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# m_name = \"DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "# model, tokenizer = load_model_and_tokenizer(m_name)\n",
    "model.eval()\n",
    "row = aime_df.iloc[0]\n",
    "question = row['Problem']\n",
    "ground_truth = row['Answer']\n",
    "# system_prompt = r'''Assume you are a professional mathematician.{}\\n\n",
    "# Please show your step by step reasoning in <thinking> tag, keep your solution concise skipping arithmetic details, and generate your answer as a number in <answer> tag.\\n'''\n",
    "system_prompt = r'''Assume you are a professional mathematician.{}\\n\n",
    "Please generate your answer as a number in <answer> tag.\\n'''\n",
    "prompt = system_prompt.format(question)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate with nucleus sampling (top-p sampling)\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=True,\n",
    "    top_p=0.9, \n",
    "    temperature=1.0,\n",
    "    num_return_sequences=1,\n",
    "    num_beams=1,\n",
    "    repetition_penalty=1.2,\n",
    "    #length_penalty=0,\n",
    "    renormalize_logits=True\n",
    ")\n",
    "\n",
    "# If multiple samples, use majority vote (here we simply pick the first for raw eval)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "412a095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> <think>\n",
       "> Okay, so I have this problem here with three logarithmic equations involving variables x, y, z, all positive real numbers. And I need to find the absolute value of log base 2 of (x⁴ y³ z²), expressed as m/n where m and n are coprime, then sum them up for my final answer.\n",
       "> \n",
       "> Let me write down the given equations first:\n",
       "> \n",
       "> 1) log₂( x / (yz) ) = 1/2\n",
       "> \n",
       "> 2) log₂( y / (xz) ) = 1/3\n",
       "> \n",
       "> 3) log₂( z / (xy) ) = 1/4\n",
       "> \n",
       "> And we want |log₂(x⁴ y³ z²)| which would just be something like log terms inside or outside? Well, since they're asking for an absolute value regardless, maybe it simplifies positively?\n",
       "> \n",
       "> First thought, these logs can be rewritten using properties of logarithms. Maybe express everything in exponentials... Hmm, yes!\n",
       "> \n",
       "> So let's take each equation step by step.\n",
       "> \n",
       "> Equation 1:\n",
       "> log₂( x/(yz) ) = 1/2  \n",
       "> Which means, converting from log form:  \n",
       "> x/(yz) = 2^(1/2) => sqrt(2)\n",
       "> \n",
       "> Similarly,\n",
       "> \n",
       "> Equation 2:\n",
       "> log₂(y/(xz)) = 1/3  \n",
       "> => y/(xz) = 2^(1/3) \n",
       "> \n",
       "> Equation 3:\n",
       "> log₂(z/(xy)) = 1/4  \n",
       "> => z/(xy) = 2^(1/4 )\n",
       "> \n",
       "> Alright, now rewrite these into fractions instead of roots if needed but maybe multiplication is easier when dealing with ratios.\n",
       "> \n",
       "> From Equation 1:  \n",
       "> x = yz * sqrt(2) ... Let me note that expression (A). So x equals y times z multiplied by root two.\n",
       "> \n",
       "> Equation 2:  \n",
       "> y = xz * 2^{1/3} ...(B)\n",
       "> Equation 3:  \n",
       "> z = xy * 2^{1/4 }...(C)\n",
       "> \n",
       "> Now, substitute (A) into Equations B and C...\n",
       "> \n",
       "> Starting with substitution into Equation B:\n",
       "> \n",
       "> We know from A, x = y*z*sqrt(2).\n",
       "> \n",
       "> Plug into Equation B: y = x*z*(2)^{1/3}\n",
       "> \n",
       "> Substitute x: y = ( y z sqrt(2) )* z * (2)^{1/3 }\n",
       "> \n",
       "> Simplify the right side: multiply constants together and same bases: y = y * z² * (sqrt(2))*(2^{1/3})\n",
       "> \n",
       "> Compute exponents on 2:\n",
       "> \n",
       "> sqrt(2)=2^{1/2}, multiplying by another 2^{1/3}: total exponent becomes 5/6.\n",
       "> \n",
       "> Thus: y= y * z² * 2^{5/6}. Let me subtract y to both sides: 0=y(z² -1)* 2^{5/6}. Since y is non-zero because all variables are positive reals, therefore we must have z² =1 ⇒ z =1 (√ isn't applicable due to positivity only). So from here,z=1.\n",
       "> \n",
       "> Wait hold on; Wait after substituting x into eq B led us to conclude that either y cancels out or leads to z squared equaling one? Which gives z=1 considering positivity.\n",
       "> \n",
       "> Yes, indeed.\n",
       "> \n",
       "> So z=1. Alright.\n",
       "> \n",
       "> With z known as 1, go back to Equation A:x = y*1*√2= √2*y\n",
       "> \n",
       "> That relates x and y directly.\n",
       "> \n",
       "> Moving forward, plug z=1 into Equation C: c is also relevant.\n",
       "> \n",
       "> Equation C: z=(xy)*(2^{1/4}). But z was found as 1.\n",
       "> \n",
       "> Therefore:\n",
       "> \n",
       "> 1= x*y*(2^{1/4}) → which implies xy =2^{-1/4}= 1 over square root fourth power.\n",
       "> \n",
       "> But since we had established earlier relation between x and y, i.e., x= sqrt(2)y, plugging into above: \n",
       "> \n",
       "> (xy)= (sqrt(2) y)( y )= sqrt(2)*y² =1/(2^{1/4})  \n",
       "> \n",
       "> Hence, solve for y²:\n",
       "> \n",
       "> Multiply both sides by 2^{1/4}: sqrt(2)*y² *2^{1/4} ?\n",
       "> \n",
       "> Wait no, wait more precisely: From xy = [1]/[2^{1/4}], while x=sqrt(2)y.\n",
       "> \n",
       "> So replace x with sqrt(2)y: Therefore:\n",
       "> \n",
       "> (sqrt(2)y)(y)= sqrt(2)y² = 1/[2^{1/4}] \n",
       "> \n",
       "> Divide sqrt(2) denominator is 2^{1/2}; numerator has factor sqrt(2): which may help cancel denominators.\n",
       "> \n",
       "> Expressed differently: compute how does sqrt(2)/2^{1/4} look?\n",
       "> \n",
       "> Note that sqrt(2) is 2^{1/2}, divided by 2^{1/4} is equivalent to 2^{(1/"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "to_markdown(tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ff46104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "row = aime_df.iloc[0]\n",
    "question = row['Problem']\n",
    "ground_truth = row['Answer']\n",
    "# system_prompt = r'''Assume you are a professional mathematician.{}\\n\n",
    "# Please show your step by step reasoning in <thinking> tag, keep your solution concise skipping arithmetic details, and generate your answer as a number in <answer> tag.\\n'''\n",
    "system_prompt = r'''Assume you are a professional mathematician.{}\\n\n",
    "Please generate your answer as a number in <answer> tag.\\n'''\n",
    "prompt = system_prompt.format(question)\n",
    "judge_prompt = r\"\"\"\n",
    "now we based on the response in <response>, could you judge its correctness in terms of closeness to goal from 1 to 10 in <score>.\n",
    "\"\"\"\n",
    "\n",
    "answer = tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, '')\n",
    "judge_string = 'Q:' + prompt + r'\\n' + r'<response>' + answer + r'<\\response>' + '\\n\\n\\n' + judge_prompt\n",
    "inputs = tokenizer(judge_string, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate with nucleus sampling (top-p sampling)\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=True,\n",
    "    top_p=0.9, \n",
    "    temperature=1.0,\n",
    "    num_return_sequences=1,\n",
    "    num_beams=1,\n",
    "    repetition_penalty=1.2,\n",
    "    #length_penalty=0,\n",
    "    renormalize_logits=True\n",
    ")\n",
    "\n",
    "# If multiple samples, use majority vote (here we simply pick the first for raw eval)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "267252c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> </think>\n",
       "> \n",
       "> The user provided mathematical reasoning towards finding \\( |\\log_2(x^4 y^3 z^2)| \\). Through successive substitutions and transformations, solutions were derived systematically, ultimately yielding precise numerical results within constraints. Based on the detailed thought processes, confident conclusions emerge upon evaluation.\n",
       "> \n",
       "> \n",
       "> \\boxed{\\dfrac{8}{7}}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(tokenizer.decode(outputs[0], skip_special_tokens=True).replace(judge_string, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf77ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
